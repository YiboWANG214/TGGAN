{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-04 05:54:39,335 - INFO - is GPU available? True\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from tggan import *\n",
    "from utils import *\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges = np.loadtxt('outputs-scale-free-nodes-100-samples-200/scale-free-nodes-100-samples-200_train.txt')\n",
    "train_edges = np.loadtxt('outputs-scale-free-nodes-100-samples-200/scale-free-nodes-100-samples-200_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 100\n",
    "rw_len = 8\n",
    "t_end = 1.\n",
    "t0 = 0.1\n",
    "edge_contact_time = t0*0.5\n",
    "batch_size = 32\n",
    "gpu_id = 0\n",
    "embedding_size = 32\n",
    "lr = 0.003\n",
    "use_decoder = 'deep'\n",
    "constraint_method = 'min_max'\n",
    "scale = 0.1\n",
    "init_walk_method = 'uniform'\n",
    "use_wgan = True\n",
    "n_eval_loop = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 9, 3)\n"
     ]
    }
   ],
   "source": [
    "walker = TemporalWalker(n_nodes, train_edges, t_end, scale, rw_len, batch_size, init_walk_method=init_walk_method)\n",
    "print(walker.walk().__next__().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tggan = TGGAN(N=n_nodes, rw_len=rw_len,\n",
    "                      t_end=t_end,\n",
    "                      edge_contact_time=edge_contact_time,\n",
    "                      walk_generator=walker.walk, batch_size=batch_size, gpu_id=gpu_id,\n",
    "                      noise_type=\"Gaussian\",\n",
    "                      disc_iters=3,\n",
    "                      W_down_discriminator_size=embedding_size,\n",
    "                      W_down_generator_size=embedding_size,\n",
    "                      l2_penalty_generator=1e-7,\n",
    "                      l2_penalty_discriminator=5e-5,\n",
    "                      generator_x_up_layers=[64],\n",
    "                      generator_t0_up_layers=[128],\n",
    "                      generator_tau_up_layers=[128],\n",
    "                      generator_layers=[100, 20],\n",
    "                      discriminator_layers=[80, 20],\n",
    "                      temp_start=5,\n",
    "                      learning_rate=lr,\n",
    "                      use_gumbel=True,\n",
    "                      use_wgan=use_wgan,\n",
    "                      wasserstein_penalty=10,\n",
    "                      use_decoder=use_decoder,\n",
    "                      constraint_method=constraint_method,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(tggan.session, \n",
    "                  \"snapshots-scale-free-nodes-100-samples-200/simulation-_iter_10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-04 05:56:29,188 - INFO - eval_iters: 0 eval_loop: 22\n",
      "2020-06-04 05:56:29,190 - INFO - eval node logit min: -1.1656744480133057 max: 1.4816631078720093\n",
      "2020-06-04 05:56:29,191 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [62 79 87 82 32 95 55 83 58 16 15 76 81 91 92  5], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:56:29,192 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [49 40  3 12 26 39  0 87 75 50 98 28 97 26 91 14], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:56:29,194 - INFO - eval_iters: 0 eval_loop: 23\n",
      "2020-06-04 05:56:29,195 - INFO - eval node logit min: -1.1656744480133057 max: 1.4816631078720093\n",
      "2020-06-04 05:56:29,196 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [87 82 32 95 55 83 58 16 15 76 81 91 92  5  0 24], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:56:29,197 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [ 3 12 26 39  0 87 75 50 98 28 97 26 91 14 74 76], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:56:29,200 - INFO - eval_iters: 0 eval_loop: 24\n",
      "2020-06-04 05:56:29,201 - INFO - eval node logit min: -1.1656744480133057 max: 1.4816631078720093\n",
      "2020-06-04 05:56:29,202 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [32 95 55 83 58 16 15 76 81 91 92  5  0 24 23 35], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:56:29,204 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [26 39  0 87 75 50 98 28 97 26 91 14 74 76 43 77], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n"
     ]
    }
   ],
   "source": [
    "eval_transitions=1e6\n",
    "p = 10\n",
    "n_smpls = tggan.batch_size * p\n",
    "# n_eval_iters = int(eval_transitions / n_smpls)\n",
    "n_eval_iters = 1\n",
    "\n",
    "sample_many = tggan.generate_discrete(batch_size*10, reuse=True, \n",
    "                                      edge_contact_time=edge_contact_time,n_eval_loop=n_eval_loop)\n",
    "fake_graphs, fake_x_t0 = tggan.get_fake_graphs(sample_many, n_smpls, n_eval_iters, n_eval_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2530, 4)\n"
     ]
    }
   ],
   "source": [
    "print(convert_graphs(fake_graphs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-04 05:09:07,802 - INFO - eval_iters: 0 eval_loop: 22\n",
      "2020-06-04 05:09:07,803 - INFO - eval node logit min: -1.1131410598754883 max: 1.4473310708999634\n",
      "2020-06-04 05:09:07,804 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [77 63 58 18 90 69 85 20  4 42 96 99 58 59 12 71], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:09:07,805 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [35 64 95 47  6 94 95 72 82 29 69 90 60 31 77 12], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:09:07,806 - INFO - eval_iters: 0 eval_loop: 23\n",
      "2020-06-04 05:09:07,807 - INFO - eval node logit min: -1.1131410598754883 max: 1.4473310708999634\n",
      "2020-06-04 05:09:07,807 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [58 18 90 69 85 20  4 42 96 99 58 59 12 71 12 55], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:09:07,808 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [95 47  6 94 95 72 82 29 69 90 60 31 77 12 11 22], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n",
      "2020-06-04 05:09:07,809 - INFO - eval_iters: 0 eval_loop: 24\n",
      "2020-06-04 05:09:07,810 - INFO - eval node logit min: -1.1131410598754883 max: 1.4473310708999634\n",
      "2020-06-04 05:09:07,811 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [90 69 85 20  4 42 96 99 58 59 12 71 12 55 74 38], [0. 0. 0. 0. 0. 0. 0. 0.], 0]\n",
      "2020-06-04 05:09:07,812 - INFO - generated [x, t0, e, tau, end]\n",
      "[0, 0.0, [ 6 94 95 72 82 29 69 90 60 31 77 12 11 22 30 32], [0. 0. 0. 0. 0. 0. 0. 0.], 1]\n"
     ]
    }
   ],
   "source": [
    "eval_transitions=1e6\n",
    "p = 10\n",
    "n_smpls = tggan.batch_size * p\n",
    "# n_eval_iters = int(eval_transitions / n_smpls)\n",
    "n_eval_iters = 1\n",
    "\n",
    "sample_many = tggan.generate_discrete(batch_size*10, reuse=True, \n",
    "                                      edge_contact_time=edge_contact_time,n_eval_loop=n_eval_loop)\n",
    "\n",
    "fake_graphs = []\n",
    "fake_x_t0 = []\n",
    "real_walks = []\n",
    "real_x_t0 = []\n",
    "for q in range(n_eval_iters):\n",
    "    fake_outputs, node_logit = tggan.session.run([\n",
    "        sample_many, tggan.logit], {tggan.temp: 0.5})\n",
    "    fake_x, fake_t0, fake_edges, fake_t, fake_end = fake_outputs\n",
    "    smpls = None\n",
    "    stop = [False] * n_smpls\n",
    "    for i in range(n_eval_loop):\n",
    "        x, t0, e, tau, le = fake_x[i], fake_t0[i], fake_edges[i], fake_t[i], fake_end[i]\n",
    "\n",
    "        if q == 0 and i >= n_eval_loop-3:\n",
    "            log('eval_iters: {} eval_loop: {}'.format(q, i))\n",
    "            log('eval node logit min: {} max: {}'.format(node_logit.min(), node_logit.max()))\n",
    "            log('generated [x, t0, e, tau, end]\\n[{}, {}, {}, {}, {}]'.format(\n",
    "                x[0], t0[0, 0], e[0, :], tau[0, :, 0], le[0]\n",
    "            ))\n",
    "            log('generated [x, t0, e, tau, end]\\n[{}, {}, {}, {}, {}]'.format(\n",
    "                x[1], t0[1, 0], e[1, :], tau[1, :, 0], le[1]\n",
    "            ))\n",
    "\n",
    "        e = e.reshape(-1, tggan.rw_len, 2)\n",
    "        tau = tau.reshape(-1, tggan.rw_len, 1)\n",
    "        if i == 0:\n",
    "            smpls = np.concatenate([e, tau],axis=-1)\n",
    "        else:\n",
    "            new_pred = np.concatenate([e[:, -1:], tau[:, -1:]], axis=-1)\n",
    "            smpls = np.concatenate([smpls, new_pred], axis=1)\n",
    "\n",
    "        # judge if reach max length\n",
    "        for b in range(n_smpls):\n",
    "            b_le = le[b]\n",
    "\n",
    "            if i == 0 and b_le == 1:  # end\n",
    "                stop[b] = True\n",
    "            if i > 0 and stop[b]:  # end\n",
    "                smpls[b, -1, :] = -1\n",
    "            if i > 0 and not stop[b] and b_le == 1:\n",
    "                stop[b] = True\n",
    "\n",
    "    fake_x = np.array(fake_x).reshape(-1, 1)\n",
    "    fake_t0 = np.array(fake_t0).reshape(-1, 1)\n",
    "    fake_len = np.array(fake_end).reshape(-1, 1) # change to end\n",
    "    fake_start = np.c_[fake_x, fake_t0, fake_len]\n",
    "    fake_x_t0.append(fake_start)\n",
    "    fake_graphs.append(smpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[34.       77.        0.026708]\n",
      "  [72.       63.        0.001126]\n",
      "  [ 4.        9.        0.000019]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]\n",
      "\n",
      " [[12.       62.        0.054622]\n",
      "  [52.       57.        0.005634]\n",
      "  [32.       41.        0.00013 ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 3.       42.        0.040148]\n",
      "  [35.       27.        0.004854]\n",
      "  [92.       20.        0.000137]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.       45.        0.072849]\n",
      "  [95.       44.        0.003608]\n",
      "  [46.       98.        0.000082]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]\n",
      "\n",
      " [[66.       36.        0.083236]\n",
      "  [69.       45.        0.009884]\n",
      "  [98.       17.        0.000261]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 7.       84.        0.048531]\n",
      "  [66.       84.        0.000435]\n",
      "  [86.       33.        0.000008]\n",
      "  ...\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.      ]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(fake_graphs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-acd4167a9c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_many\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnetgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "sample_many = tggan.generate_discrete(batch_size*10, reuse=True, \n",
    "                                      edge_contact_time=edge_contact_time,n_eval_loop=n_eval_loop)\n",
    "samples = []\n",
    "for i in range(1, 2):\n",
    "    if i % 500 == 0:\n",
    "        print(i+1)\n",
    "    samples.append(sample_many.eval({tggan.tau: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
